model:
  internvl_path: /data/phd/jinjiachun/ckpt/OpenGVLab/InternVL3_5-1B
  high_dim: 4096
  down_dim: 16
  diffhead:
    x_dim: 16
    hidden_size: 512
    z_dim: 1024
    depth: 16
  train_llm: true

# --------------------------------------------------
train:
  root: /data/phd/jinjiachun/experiment
  resume_path: /data/phd/jinjiachun/experiment/down_proj/0916_llava_distill_linear_debug/internvl-down_proj-100000
  global_step: 0

  exp_name: &exp_name down_proj_optimized
  proj_name: *exp_name
  output_dir: 0917_joint_training_optimized
  logging_dir: logs
  mixed_precision: bf16
  gradient_accumulation_steps: 2  # 增加梯度累积步数以提高GPU利用率
  report_to: swanlab

  lr: 1e-4
  num_iter: 500000
  save_every: 1000

  hp_loss_gen: 1.0
  hp_loss_und: 1.0

data:
  batch_size: &batch_size 16  # 稍微减小batch size以允许更多并行
  gen:
    wds_path: [/data/phd/jinjiachun/dataset/BLIP3o/BLIP3o-Pretrain-Long-Caption, /data/phd/jinjiachun/dataset/BLIP3o/BLIP3o-Pretrain-Short-Caption, /data/phd/jinjiachun/dataset/BLIP3o/BLIP3o-Pretrain-JourneyDB]
    img_size: 448
    cfg_drop_rate: 0.1
    num_img_token: 256
    max_seq_length: 512
    buffer_size: 20000  # 增加缓冲区大小
    batch_size: *batch_size
    num_workers: 12  # 增加worker数量
  und:
    batch_size: 12  # 增加理解任务的batch size
    num_workers: 12  # 增加worker数量
    max_seq_length: 1024

